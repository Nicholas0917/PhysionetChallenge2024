#!/bin/bash --login
#$ -cwd              # Job will run in currect directory
                     # Nothing specified to request more cores = default 1 core
#$ -l nvidia_v100=1  # Request GPU with 1 core (can be 1-4)
                     # Can also request nvidia_a100 but good luck with the queue
# $ -pe smp.pe N     # remove space at start of line to run as parallel job with N cpu cores

#$ -o jobscripts/logs/   # put outputs in logs folder
#$ -e jobscripts/logs/                    

# Load any required modulefiles
source ~/envs/physionet2024/bin/activate
module load libs/cuda/12.2.2
module load compilers/gcc/6.4.0

# Copy a directory of files from scratch to the GPU node's local NVMe storage
rsync -av --progress ~/scratch/PhysionetChallenge2024/ $TMPDIR --exclude temp_data --exclude .git --exclude ptb-xl
cd $TMPDIR/PhysionetChallenge2024/
echo "Copy complete. Starting job with $NGPUS GPU(s) with ID(s) $CUDA_VISIBLE_DEVICES and $NSLOTS CPU core(s)."

# Run code
python tests/yolo_train.py

# Copy the results back to the main scratch area
cp -r runs ~/scratch/PhysionetChallenge2024/
cp -r test_data/yolo_images/test ~/scratch/PhysionetChallenge2024/test_data/yolo_images/
cp -r test_data/yolo_labels/test ~/scratch/PhysionetChallenge2024/test_data/yolo_labels/
